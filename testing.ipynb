{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mae.decoder import  *\n",
    "from mae.encoder import *\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_config = EncoderConfig(\n",
    "    image_size=224,\n",
    "    hidden_size=768,\n",
    "    intermediate_size=3072,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    num_channels=3,\n",
    "    patch_size=16,\n",
    "    layer_norm_eps=1e-6,\n",
    "    attention_dropout=0.0,\n",
    "    num_image_tokens=None,\n",
    "    do_random_mask=True,\n",
    "    mask_ratio=0.75\n",
    ")\n",
    "\n",
    "decoder_config = DecoderConfig(\n",
    "    image_size=224,\n",
    "    in_proj_dim=768,\n",
    "    hidden_size=768,\n",
    "    intermediate_size=3072,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    num_channels=3,\n",
    "    patch_size=16,\n",
    "    layer_norm_eps=1e-6,\n",
    "    attention_dropout=0.0,\n",
    "    do_loss_calculation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderModel(encoder_config)\n",
    "decoder = DecoderModel(decoder_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torchvision.io.read_image(\"dog.jpg\")\n",
    "# resize image to 224x224\n",
    "img = torchvision.transforms.functional.resize(img, (224, 224)).unsqueeze(0)\n",
    "# normalize image\n",
    "img = img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 224, 224])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = img.repeat(2, 1, 1, 1)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 49, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_op, mask, ids_restore = encoder(img)\n",
    "encoder_op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 224, 224]),\n",
       " torch.Size([]),\n",
       " tensor(0.8701, grad_fn=<MseLossBackward0>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op, loss = decoder((encoder_op, mask, ids_restore), img)\n",
    "op.shape, loss.shape, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.7226,  0.3313, -0.4810,  ...,  0.0546, -0.6842, -0.0195],\n",
       "          [ 0.5536, -0.8628,  0.4235,  ..., -0.6943,  0.8448, -0.1242],\n",
       "          [-0.3881, -0.0930,  0.0834,  ...,  1.0735, -0.3513, -0.1858],\n",
       "          ...,\n",
       "          [-0.8425,  0.7944,  0.4843,  ..., -0.6284, -1.2117, -0.4688],\n",
       "          [-0.1908, -0.0426,  0.0454,  ...,  0.4292, -0.7883,  0.2271],\n",
       "          [ 0.1726, -0.0528, -1.1564,  ...,  0.6047, -0.0196, -0.2510]],\n",
       "\n",
       "         [[-0.2031,  0.1729,  0.4070,  ...,  0.3841, -0.7907,  0.0975],\n",
       "          [-0.0536, -0.4314,  0.0327,  ...,  0.6603,  0.2337,  0.1603],\n",
       "          [ 0.4947, -0.2547, -0.2665,  ...,  0.1633, -0.6230,  0.0787],\n",
       "          ...,\n",
       "          [ 0.4314, -0.6206,  0.5678,  ..., -1.0114, -0.5201, -0.4156],\n",
       "          [-0.1480, -0.0195, -0.1213,  ..., -0.3604, -0.2285, -0.1394],\n",
       "          [ 0.2935,  0.5748,  0.2411,  ..., -0.1690,  0.2752, -0.1123]],\n",
       "\n",
       "         [[-0.7959,  0.2464,  0.6870,  ...,  0.4973,  0.3346,  0.5141],\n",
       "          [ 0.4473,  0.0768, -0.1841,  ..., -1.3627,  0.3575,  0.3454],\n",
       "          [-1.3369, -0.7315,  0.5366,  ...,  0.5390, -0.5523, -1.1566],\n",
       "          ...,\n",
       "          [-1.5717, -0.0243,  0.0529,  ...,  0.4350,  0.4042, -0.0183],\n",
       "          [-0.1109, -0.4401,  0.2007,  ...,  0.9364, -0.4434,  0.9813],\n",
       "          [-0.3886,  0.4648,  0.2546,  ...,  0.9161, -1.2878,  1.4751]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2412,  0.5267, -0.2331,  ...,  0.3057, -0.4888,  0.3037],\n",
       "          [-0.0376, -0.2830,  0.7830,  ..., -0.8687,  0.8752, -0.3263],\n",
       "          [ 0.0151,  0.8511, -1.0334,  ...,  1.1680, -0.0885, -0.1615],\n",
       "          ...,\n",
       "          [-0.7144,  0.8502,  0.1383,  ...,  0.6263, -1.0658, -0.4789],\n",
       "          [-0.2916,  0.0825, -0.0932,  ..., -0.3680, -0.4988, -0.4248],\n",
       "          [ 0.4636, -0.5145, -1.2767,  ...,  0.9509, -0.0132, -0.0737]],\n",
       "\n",
       "         [[-0.3178, -0.1746,  0.7460,  ...,  0.0870, -0.8345,  0.0279],\n",
       "          [-1.0854, -0.0919, -0.8928,  ...,  0.3060,  0.1910,  0.3412],\n",
       "          [ 0.3437, -0.1271, -0.5795,  ..., -0.0567, -0.8866,  0.2727],\n",
       "          ...,\n",
       "          [ 0.4282, -0.3766,  0.1643,  ..., -0.4281,  0.3851,  0.4980],\n",
       "          [-0.3917, -0.3734,  0.0321,  ..., -0.5272, -0.6830, -0.2032],\n",
       "          [-0.0105,  0.5141,  0.0569,  ..., -0.0306, -0.4383, -0.3464]],\n",
       "\n",
       "         [[-0.1580, -0.3913, -0.8097,  ...,  0.3497,  0.3216,  0.1987],\n",
       "          [ 0.4958, -0.5173, -0.1623,  ..., -1.4793,  0.3705,  0.4433],\n",
       "          [-1.9380, -0.6389,  0.4026,  ...,  0.1381, -0.2339, -0.9032],\n",
       "          ...,\n",
       "          [-1.4861,  0.0572,  0.4023,  ...,  0.7469,  0.8905, -0.5110],\n",
       "          [ 0.0177, -0.3710,  0.0498,  ...,  0.3554, -0.3490,  0.5317],\n",
       "          [-0.8481,  0.6826,  0.1303,  ...,  0.6305, -1.4129,  1.6442]]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
