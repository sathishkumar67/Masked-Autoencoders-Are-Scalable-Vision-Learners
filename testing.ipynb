{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mae.decoder import  *\n",
    "from mae.encoder import *\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_config = EncoderConfig(\n",
    "    image_size=224,\n",
    "    hidden_size=768,\n",
    "    intermediate_size=3072,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    num_channels=3,\n",
    "    patch_size=16,\n",
    "    layer_norm_eps=1e-8,\n",
    "    attention_dropout=0.0,\n",
    "    num_image_tokens=None,\n",
    "    do_random_mask=False,\n",
    "    mask_ratio=0.75\n",
    ")\n",
    "\n",
    "decoder_config = DecoderConfig(\n",
    "    image_size=224,\n",
    "    in_proj_dim=768,\n",
    "    hidden_size=768,\n",
    "    intermediate_size=3072,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    num_channels=3,\n",
    "    patch_size=16,\n",
    "    layer_norm_eps=1e-8,\n",
    "    attention_dropout=0.0,\n",
    "    do_loss_calculation=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderModel(encoder_config)\n",
    "decoder = DecoderModel(decoder_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torchvision.io.read_image(\"dog.jpg\")\n",
    "# resize image to 224x224\n",
    "img = torchvision.transforms.functional.resize(img, (224, 224)).unsqueeze(0)\n",
    "# normalize image\n",
    "img = img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = img.repeat(2, 1, 1, 1)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 196, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_op, mask, ids_restore = encoder(img)\n",
    "encoder_op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 224, 224]), None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op, loss = decoder((encoder_op, mask, ids_restore), img)\n",
    "op.shape, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0803,  0.1212, -1.0792,  ...,  0.0895, -0.1893,  0.2833],\n",
       "          [-0.4466,  0.7161,  0.4436,  ...,  0.8274,  0.1024, -0.2308],\n",
       "          [-0.3762, -0.3539, -0.4450,  ..., -0.9515, -0.6690, -0.2326],\n",
       "          ...,\n",
       "          [ 0.2359, -1.0694, -0.0058,  ...,  1.2715, -0.6000,  0.1574],\n",
       "          [-1.0460,  0.7951, -0.9496,  ...,  0.9215, -0.4596,  0.0249],\n",
       "          [-0.9521,  1.2195, -0.5152,  ..., -0.0985, -0.0838, -0.1849]],\n",
       "\n",
       "         [[ 0.4451, -0.6161, -0.2058,  ..., -0.2029,  0.1858,  0.1745],\n",
       "          [-0.1391, -0.2809, -0.3045,  ...,  0.6473,  0.0908, -0.1560],\n",
       "          [ 0.4616, -0.2726, -0.4020,  ..., -0.2546,  0.3106, -0.2373],\n",
       "          ...,\n",
       "          [ 0.4425, -0.3242,  0.9490,  ...,  0.2141,  0.4529,  0.8602],\n",
       "          [ 0.3228,  0.2255,  1.1811,  ..., -0.3888,  1.2466,  0.8956],\n",
       "          [-0.2798,  0.3041, -0.0846,  ...,  0.5497, -0.1276, -0.4146]],\n",
       "\n",
       "         [[-0.2066,  0.1005, -0.1012,  ...,  0.1073,  0.0664, -1.0251],\n",
       "          [ 0.6611, -0.6934, -0.0596,  ...,  0.0196, -0.6023, -0.3564],\n",
       "          [-0.6971, -0.2361, -0.3944,  ...,  0.4559, -0.8439, -0.8039],\n",
       "          ...,\n",
       "          [ 0.0747, -0.1059, -0.7053,  ...,  0.3132, -0.6132, -0.8910],\n",
       "          [-0.4631, -0.8914, -0.5996,  ..., -0.4253, -1.4187,  0.2408],\n",
       "          [ 0.5531,  0.3477, -0.0913,  ...,  0.3209, -0.9068,  0.5009]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0803,  0.1212, -1.0792,  ...,  0.0895, -0.1893,  0.2833],\n",
       "          [-0.4466,  0.7161,  0.4436,  ...,  0.8274,  0.1024, -0.2308],\n",
       "          [-0.3762, -0.3539, -0.4450,  ..., -0.9515, -0.6690, -0.2326],\n",
       "          ...,\n",
       "          [ 0.2359, -1.0694, -0.0058,  ...,  1.2715, -0.6000,  0.1574],\n",
       "          [-1.0460,  0.7951, -0.9496,  ...,  0.9215, -0.4596,  0.0249],\n",
       "          [-0.9521,  1.2195, -0.5152,  ..., -0.0985, -0.0838, -0.1849]],\n",
       "\n",
       "         [[ 0.4451, -0.6161, -0.2058,  ..., -0.2029,  0.1858,  0.1745],\n",
       "          [-0.1391, -0.2809, -0.3045,  ...,  0.6473,  0.0908, -0.1560],\n",
       "          [ 0.4616, -0.2726, -0.4020,  ..., -0.2546,  0.3106, -0.2373],\n",
       "          ...,\n",
       "          [ 0.4425, -0.3242,  0.9490,  ...,  0.2141,  0.4529,  0.8602],\n",
       "          [ 0.3228,  0.2255,  1.1811,  ..., -0.3888,  1.2466,  0.8956],\n",
       "          [-0.2798,  0.3041, -0.0846,  ...,  0.5497, -0.1276, -0.4146]],\n",
       "\n",
       "         [[-0.2066,  0.1005, -0.1012,  ...,  0.1073,  0.0664, -1.0251],\n",
       "          [ 0.6611, -0.6934, -0.0596,  ...,  0.0196, -0.6023, -0.3564],\n",
       "          [-0.6971, -0.2361, -0.3944,  ...,  0.4559, -0.8439, -0.8039],\n",
       "          ...,\n",
       "          [ 0.0747, -0.1059, -0.7053,  ...,  0.3132, -0.6132, -0.8910],\n",
       "          [-0.4631, -0.8914, -0.5996,  ..., -0.4253, -1.4187,  0.2408],\n",
       "          [ 0.5531,  0.3477, -0.0913,  ...,  0.3209, -0.9068,  0.5009]]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
